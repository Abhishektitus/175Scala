Problem Scenario 25 : You have been given below comma separated employee information. That needs to be added in /home/cloudera/flumetest/in.txt file (to do tail source) 
sex,name,city 
1,alok,mumbai 
1,jatin,chennai 
1,yogesh,kolkata 
2,ragini,delhi 
2,jyotsana,pune 
1,valmiki,banglore 

Create a flume conf file using fastest non-durable channel, which write data in hive warehouse directory, in two separate tables called flumemaleemployee1 and flumefemaleemployee1 
(Create hive table as well tor given data). Please use tail source with /home/cloudera/flumetest/in.txt file. 
flumemaleemployee1 : will contain only male employees data 
flumetemaleemployee1 : Will contain only woman employees data
===================================================================== 
Solution : 
Step 1 : Create hive table tor flumemaleemployee1 and .' 
CREATE TABLE flumemaleemployee1
{
Sex_type int , 
name string, 
city string 
}
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ‘,’ ; 

CREATE TABLE flumefemaleemployee1
{
Sex_type int , 
name string, 
city string 
}
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ‘,’; 
Step 2 : Create below directory and file 
mkdir /home/cloudera/flumetest/ 
cd /home/cloudera/flumetest/ 
Step 3 : Create flume configuration file, with below configuration for source, sink and channel and save it in flume5.conf.  
agent.channels = mem1 mem2 
agent.sinks = std1 std2 
agent.sources.tailsrc.type = exec 
agent.sources.tailsrc.command = tail -F /home/cloudera/flumetest/in.txt 
agent.sources.tailsrc.batchSize = 1 
agent.sources.tailsrc.interceptors = i1 
agent.sources.tailsrc.interceptors.i1 .type = regex_extractor 
agent.sources.tailsrc.interceptors.il .regex = ^(\\d) 
agent.sources.tailsrc.interceptors.il .serializers = t1
agent.sources.tailsrc.interceptors.il. serializers.t1 .name = type 
agent. sources.tailsrc.selector.type = multiplexing
agent.sources.tailsrc.selector.header = type 
agent.sources.tailsrc.selector.mapping.l = mem1
agent.sources.tailsrc.selector.mapping.2 = mem2 
agent.sinks.std1.type = hdfs 
agent.sinks.std1 .channel = mem1
agent.sinks.std1.batchSize = 1 
agent.sinks.std1 .hdfs.path = /user/hive/warehouse/flumemaleemployee1
agent.sinks.std1 .rolllnterval = 0 
agent.sinks.std1 .hdfs.fileType = DataStream 
agent.sinks.std2.type = hdfs 
agent.sinks.std2.channel = mem2 
agent.sinks.std2.batchSize = 1 
agent.sinks.std2.hdts.path = /user/hive/warehouse/flumetemaleemployee1
agent.sinks.std2.rolllnterval = 0 
agent.sinks.std2.hdfs.fileType = DataStream 
agent.channels.mem1.type = memory 
agent.channels.mem1.capacity = 100 
agent.channels.mem2.type = memory 
agent.channels.mem2.capacity = 100 
agent.sources.tailsrc.channels = mem1 mem2 

Step 4 : Run below command which will use this configuration file and append data in hdfs. 
Start flume service : 
flume-ng agent --conf /home/cloudera/flumeconf --cont-file /home/cloudera/flumecont/flume5.conf --name agent 
Step 5 : Open another terminal create a file at /home/cloudera/flumetest/in.txt . 
Step 6 : Enter below data in tile and save it. 
1,alok,mumbai 
1,jatin,chennai 
1,yogesh,kolkata 
2,ragini,delhi 
2,jyotsana,pune 
1,valmiki,banglore 
Step 7: open hue and check the data is available in hive table  or not.
Step8: Stop flume service by  pressing ctrl+c
